{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EM, SDI, and FE Multi-Output Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up Data Loaders\n",
    "Set up DataLoader objects for the training, validation, and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None, scaler=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.annotations = pd.read_csv(csv_file, header=None, names=['EM', 'SDI', 'FE'])\n",
    "        \n",
    "        # Filter out rows where the corresponding image does not exist\n",
    "        def file_exists(idx):\n",
    "            file_path = os.path.join(root_dir, f\"{idx}LD_Data.png\")\n",
    "            exists = os.path.isfile(file_path)\n",
    "            if not exists:\n",
    "                print(f\"File not found: {file_path}\")\n",
    "            return exists\n",
    "        \n",
    "        self.annotations = self.annotations[\n",
    "            self.annotations.index.to_series().apply(file_exists)\n",
    "        ]\n",
    "\n",
    "        # Initialize the scaler and fit it on the combined target values (EM, SDI, FE)\n",
    "        self.scaler = scaler\n",
    "        if self.scaler is not None:\n",
    "            combined_values = self.annotations[['EM', 'SDI', 'FE']].values\n",
    "            self.scaler.fit(combined_values)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, f\"{self.annotations.index[idx]}LD_Data.png\")\n",
    "        image = Image.open(img_name).convert(\"RGB\")\n",
    "        em = self.annotations.iloc[idx, 0]\n",
    "        sdi = self.annotations.iloc[idx, 1]\n",
    "        fe = self.annotations.iloc[idx, 2]\n",
    "        \n",
    "        # Normalize/Standardize the combined target values (EM, SDI, FE)\n",
    "        if self.scaler is not None:\n",
    "            combined_values = self.scaler.transform([[em, sdi, fe]])[0]\n",
    "            em, sdi, fe = combined_values\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, (em, sdi, fe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load images and FEA input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Define data transformations\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # Resize directly to 224x224\n",
    "        transforms.RandomHorizontalFlip(),  # Randomly flip the image horizontally\n",
    "        transforms.ToTensor(),  # Convert the image to a tensor\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalize with mean and std\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # Resize directly to 224x224\n",
    "        transforms.ToTensor(),  # Convert the image to a tensor\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalize with mean and std\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # Resize directly to 224x224\n",
    "        transforms.ToTensor(),  # Convert the image to a tensor\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalize with mean and std\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Define the data directory and CSV file\n",
    "data_dir = 'SimulationImages'\n",
    "csv_file = 'InputParameters.csv'\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Create the full dataset\n",
    "full_dataset = CustomImageDataset(csv_file, data_dir, data_transforms['train'], scaler=scaler)\n",
    "\n",
    "# Calculate the sizes for training, validation, and test sets\n",
    "total_size = len(full_dataset)\n",
    "train_size = int(0.80 * total_size)\n",
    "val_size = int(0.18 * total_size)\n",
    "test_size = total_size - train_size - val_size\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset, val_dataset, test_dataset = random_split(full_dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Apply the appropriate transformations to each subset\n",
    "train_dataset.dataset.transform = data_transforms['train']\n",
    "val_dataset.dataset.transform = data_transforms['val']\n",
    "test_dataset.dataset.transform = data_transforms['test']\n",
    "\n",
    "# Create dataloaders\n",
    "dataloaders = {\n",
    "    'train': DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0),\n",
    "    'val': DataLoader(val_dataset, batch_size=32, shuffle=True, num_workers=0),\n",
    "    'test': DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)  # Set shuffle to False\n",
    "}\n",
    "\n",
    "# Get dataset sizes\n",
    "dataset_sizes = {x: len(dataloaders[x].dataset) for x in ['train', 'val', 'test']}\n",
    "\n",
    "# Print dataset sizes\n",
    "print(f\"Training set size: {dataset_sizes['train']}\")\n",
    "print(f\"Validation set size: {dataset_sizes['val']}\")\n",
    "print(f\"Test set size: {dataset_sizes['test']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning with ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "import time\n",
    "import copy\n",
    "import pickle\n",
    "\n",
    "# Load the pre-trained ResNet model if not already loaded\n",
    "resnet = models.resnet18(pretrained=True)\n",
    "\n",
    "# Modify the final fully connected layer for multi-output regression\n",
    "num_ftrs = resnet.fc.in_features\n",
    "resnet.fc = nn.Linear(num_ftrs, 3)  # Output three values: EM, SDI, and FE\n",
    "\n",
    "# Move the model to the GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet = resnet.to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()    # Mean Squared Error loss for regression\n",
    "optimizer = optim.Adam(resnet.parameters(), lr=0.001)   # Adam optimizer with a learning rate of 0.001\n",
    "\n",
    "# Training and validation function\n",
    "# The train_model function is used to train the model. It takes the model, dataloaders, criterion, optimizer, and number of epochs as input.\n",
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25):\n",
    "    since = time.time() # Get the current time\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())  # Deep copy the model weights to keep track of the best model\n",
    "    best_loss = float('inf')    # Set the best loss to infinity to ensure that the first model is saved\n",
    "\n",
    "    epoch_vect = []\n",
    "    train_vect = []\n",
    "    val_vect = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        epoch_vect.append(epoch)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0  # Initialize the running loss to 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, values in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)  # Move the inputs to the GPU if available\n",
    "                em = values[0][:].to(device).unsqueeze(1).float()   # Extract the EM value and move to GPU if available\n",
    "                sdi = values[1][:].to(device).unsqueeze(1).float()   # Extract the SDI value and move to GPU if available\n",
    "                fe = values[2][:].to(device).unsqueeze(1).float()   # Extract the FE value and move to GPU if available\n",
    "\n",
    "                # Combine the targets into a single tensor\n",
    "                targets = torch.cat((em, sdi, fe), dim=1)\n",
    "\n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                with torch.set_grad_enabled(phase == 'train'): # Set the gradients to be computed only during training\n",
    "                    outputs = model(inputs) # Compute the output of the model\n",
    "                    loss = criterion(outputs, targets)   # Compute the loss using the output of the model and the targets\n",
    "\n",
    "                    # Backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward() # Compute the gradients of the loss with respect to the model parameters\n",
    "                        optimizer.step()    # Update the model parameters using the gradients and the optimizer\n",
    "\n",
    "                # Statistics\n",
    "                running_loss += loss.item() * inputs.size(0)    # Multiply the loss by the batch size and add it to the running loss\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)   # Compute the epoch loss by dividing the running loss by the number of samples in the dataset\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f}')\n",
    "            if phase == 'train':\n",
    "                train_vect.append(epoch_loss)\n",
    "            if phase == 'val':\n",
    "                val_vect.append(epoch_loss)\n",
    "\n",
    "            # Deep copy the model\n",
    "            if phase == 'val' and epoch_loss < best_loss:   # If the phase is validation and the epoch loss is less than the best loss\n",
    "                best_loss = epoch_loss  # Update the best loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())  # Save a deep copy of the model weights\n",
    "\n",
    "        print() # Print an empty line\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')   # Print the time taken for training\n",
    "    print(f'Best val Loss: {best_loss:.4f}')    # Print the best validation loss\n",
    "    \n",
    "    with open(\"TrainLoss\", \"wb\") as fp:   #Pickling\n",
    "        pickle.dump(train_vect, fp)\n",
    "\n",
    "    with open(\"ValLoss\", \"wb\") as fp:   #Pickling\n",
    "        pickle.dump(val_vect, fp)\n",
    "    \n",
    "    # Load best model weights\n",
    "    model.load_state_dict(best_model_wts)   # Load the best model weights\n",
    "    return model\n",
    "\n",
    "# Train the model using the method defined above for the number of epochs specified below\n",
    "num_epochs = 100\n",
    "resnet = train_model(resnet, dataloaders, criterion, optimizer, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# Function to display images with true and predicted values\n",
    "def imshow(inp, ax, title=None, fontsize=12):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    ax.imshow(inp)\n",
    "    if title is not None:\n",
    "        ax.set_title(title, fontsize=fontsize)  # Set the font size of the title\n",
    "    ax.axis('off')  # Remove axes\n",
    "\n",
    "# Get a batch of test data\n",
    "inputs, targets = next(iter(dataloaders['test']))\n",
    "inputs = inputs.to(device)\n",
    "targets = torch.cat([targets[i].unsqueeze(1) for i in range(3)], dim=1).to(device).float()  # Combine EM, SDI, and FE\n",
    "\n",
    "\n",
    "# Get model predictions\n",
    "resnet.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = resnet(inputs)\n",
    "\n",
    "# Convert to CPU for visualization\n",
    "inputs = inputs.cpu()\n",
    "targets = targets.cpu()\n",
    "outputs = outputs.cpu()\n",
    "\n",
    "# Denormalize/Destandardize the predictions and true values\n",
    "targets_denorm = scaler.inverse_transform(targets.numpy())\n",
    "outputs_denorm = scaler.inverse_transform(outputs.numpy())\n",
    "\n",
    "with open(\"Target\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(targets_denorm, fp)\n",
    "\n",
    "with open(\"Output\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(outputs_denorm, fp)\n",
    "\n",
    "# Plot the images with true and predicted values for EM, SDI, and FE\n",
    "fig, axes = plt.subplots(8, 4, figsize=(32, 64))  # Increase figsize to make individual plots bigger\n",
    "axes = axes.flatten()\n",
    "for i in range(32):\n",
    "    imshow(inputs[i], ax=axes[i], title=f\"EM P: {outputs_denorm[i][0]:,.0f}, T: {targets_denorm[i][0]:,.0f}, E: {(abs(outputs_denorm[i][0] - targets_denorm[i][0]) / targets_denorm[i][0]) *100:.2f}%\\n\"\n",
    "                                        f\"SDI P: {outputs_denorm[i][1]:.5f}, T: {targets_denorm[i][1]:.5f}, E: {(abs(outputs_denorm[i][1] - targets_denorm[i][1]) / targets_denorm[i][1]) *100:.2f}%\\n\"\n",
    "                                        f\"FE P: {outputs_denorm[i][2]:.4f}, T: {targets_denorm[i][2]:.4f}, E: {(abs(outputs_denorm[i][2] - targets_denorm[i][2]) / targets_denorm[i][2]) *100:.2f}%\", fontsize=20)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.3)  # Adjust spacing between subplots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model, Weights, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import joblib  # For saving the scaler\n",
    "\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "os.makedirs('SavedModels', exist_ok=True)\n",
    "\n",
    "# Save the entire model\n",
    "torch.save(resnet, 'SavedModels/EM_SDI_FE_ResNet.pth')\n",
    "\n",
    "# Save only the model state dictionary (weights)\n",
    "torch.save(resnet.state_dict(), 'SavedModels/EM_SDI_FE_ResNet_weights.pth')\n",
    "\n",
    "# Save the scaler\n",
    "joblib.dump(scaler, 'SavedModels/EM_SDI_FE_ResNet_scaler.pkl')\n",
    "\n",
    "# Save the optimizer state\n",
    "torch.save(optimizer.state_dict(), 'SavedModels/EM_SDI_FE_ResNet_optimizer.pth')\n",
    "\n",
    "# Save the training configuration\n",
    "training_config = {\n",
    "    'learning_rate': 0.001,\n",
    "    'batch_size': 32,\n",
    "    'num_epochs': 100,\n",
    "    'seed': 42,\n",
    "    'model_architecture': 'resnet18',\n",
    "    'output_features': 3\n",
    "}\n",
    "joblib.dump(training_config, 'SavedModels/EM_SDI_FE_ResNet_config.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-Create Model and Load Saved Weights\n",
    "This is good if you go to another system that may have different versions of Pytorch or Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib  # For loading the scaler\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import copy\n",
    "import pickle\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# Define the model architecture\n",
    "resnet = models.resnet18(pretrained=False)\n",
    "num_ftrs = resnet.fc.in_features\n",
    "resnet.fc = nn.Linear(num_ftrs, 3)  # Output three values: EM, SDI, and FE\n",
    "\n",
    "# Load the model state dictionary (weights)\n",
    "resnet.load_state_dict(torch.load('SavedModels/EM_SDI_FE_ResNet_weights.pth'))\n",
    "resnet.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Move the model to the GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet = resnet.to(device)\n",
    "\n",
    "# Load the scaler used during training\n",
    "scaler = joblib.load('SavedModels/EM_SDI_FE_ResNet_scaler.pkl')  # Assuming you saved the scaler using joblib\n",
    "\n",
    "# Load the optimizer state\n",
    "optimizer = optim.Adam(resnet.parameters(), lr=0.001)  # Define the optimizer\n",
    "optimizer.load_state_dict(torch.load('SavedModels/EM_SDI_FE_ResNet_optimizer.pth'))\n",
    "\n",
    "# Load the training configuration\n",
    "training_config = joblib.load('SavedModels/EM_SDI_FE_ResNet_config.pkl')\n",
    "print(training_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image Exp01.png from the Images/Experiments folder\n",
    "# and make a prediction using the model\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "EMvector = []\n",
    "SDIvector = []\n",
    "FEvector = []\n",
    "\n",
    "\n",
    "with open('FEAInputData.csv', 'w', newline='') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, quoting=csv.QUOTE_ALL)\n",
    "\n",
    "    for ki in range(0, 12):\n",
    "        # Load the image\n",
    "        #if ki < 10:\n",
    "            #img = Image.open('Images/Experiments/0'+str(ki)+' (Unload).png').convert(\"RGB\")\n",
    "        #else:\n",
    "        img = Image.open('Experiments/'+str(ki)+'Exp.png').convert(\"RGB\")\n",
    "        # Define the transformations\n",
    "        data_transforms = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        # Apply the transformations\n",
    "        img = data_transforms(img).unsqueeze(0)\n",
    "        \n",
    "        # Move the image to the GPU if available\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        img = img.to(device)\n",
    "        \n",
    "        # Make a prediction\n",
    "        resnet.eval()\n",
    "        with torch.no_grad():\n",
    "            output = resnet(img)\n",
    "        \n",
    "        # Convert the output to CPU for further processing\n",
    "        output = output.cpu().numpy()\n",
    "        \n",
    "        # Denormalize/Destandardize the predictions\n",
    "        output_denorm = scaler.inverse_transform(output)\n",
    "        \n",
    "        EMvector.append(output_denorm[0][0])\n",
    "        SDIvector.append(output_denorm[0][1])\n",
    "        FEvector.append(output_denorm[0][2])\n",
    "\n",
    "        spamwriter.writerow([output_denorm[0][0], output_denorm[0][1], output_denorm[0][2]])\n",
    "    \n",
    "    print(EMvector)\n",
    "    print(SDIvector)\n",
    "    print(FEvector)\n",
    "    \n",
    "    print(np.multiply(EMvector, SDIvector))\n",
    "    print(np.mean(np.multiply(EMvector, SDIvector)))\n",
    "    \n",
    "    # Print the predictions\n",
    "    print(f\"EM: {output_denorm[0][0]:,.0f} MPa\")\n",
    "    print(f\"SDI: {output_denorm[0][1]:.5f} mm/mm\")\n",
    "    print(f\"FE: {output_denorm[0][2]:.4f} kJ/m^2\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Interpretation Using Captum\n",
    "\n",
    "[Captum](https://captum.ai/) (“comprehension” in Latin) is an open source, extensible library for model interpretability built on PyTorch.\n",
    "\n",
    "With the increase in model complexity and the resulting lack of transparency, model interpretability methods have become increasingly important. Model understanding is both an active area of research as well as an area of focus for practical applications across industries using machine learning. Captum provides state-of-the-art algorithms, including Integrated Gradients, to provide researchers and developers with an easy way to understand which features are contributing to a model’s output.\n",
    "\n",
    "Full documentation, an API reference, and a suite of tutorials on specific topics are available at the [captum.ai](https://captum.ai/) website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import captum\n",
    "from captum.attr import Occlusion\n",
    "from captum.attr import visualization as viz\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "test_image_number = 1\n",
    "for test_image_number in range(0,9):\n",
    "    print(test_image_number)\n",
    "    # Load the image\n",
    "    img_path = 'Images/Experiments_Update2/'+str(test_image_number)+'Exp.png'\n",
    "    input_img = Image.open(img_path).convert(\"RGB\")\n",
    "    # Define the transformations\n",
    "    data_transforms = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Apply the transformations\n",
    "    input_img = data_transforms(input_img).unsqueeze(0)\n",
    "    \n",
    "    # Move the image to the GPU if available\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    input_img = input_img.to(device)\n",
    "    \n",
    "    # Make a prediction\n",
    "    resnet.eval()\n",
    "    with torch.no_grad():\n",
    "        output = resnet(input_img)\n",
    "    \n",
    "    # Convert the output to CPU for further processing\n",
    "    output = output.cpu().numpy()\n",
    "    \n",
    "    # Denormalize/Destandardize the predictions\n",
    "    output_denorm = scaler.inverse_transform(output)\n",
    "    pred_em = outputs_denorm[test_image_number][0]\n",
    "    pred_sdi = outputs_denorm[test_image_number][1]\n",
    "    pred_fe = outputs_denorm[test_image_number][2]\n",
    "    \n",
    "    # Initialize Occlusion with the regression model\n",
    "    occlusion = Occlusion(resnet)\n",
    "    \n",
    "    # Compute the occlusion attributions for each output\n",
    "    attributions_occ_em = occlusion.attribute(input_img,\n",
    "                                              target=0,\n",
    "                                              strides=(3, 8, 8),\n",
    "                                              sliding_window_shapes=(3, 15, 15),\n",
    "                                              baselines=0)\n",
    "    \n",
    "    attributions_occ_sdi = occlusion.attribute(input_img,\n",
    "                                               target=1,\n",
    "                                               strides=(3, 8, 8),\n",
    "                                               sliding_window_shapes=(3, 15, 15),\n",
    "                                               baselines=0)\n",
    "    \n",
    "    attributions_occ_fe = occlusion.attribute(input_img,\n",
    "                                              target=2,\n",
    "                                              strides=(3, 8, 8),\n",
    "                                              sliding_window_shapes=(3, 15, 15),\n",
    "                                              baselines=0)\n",
    "    \n",
    "\n",
    "    # Transpose the attributions and input image to match the expected shape for visualization\n",
    "    attr_em = np.transpose(attributions_occ_em.squeeze().cpu().detach().numpy(), (1, 2, 0))\n",
    "    attr_sdi = np.transpose(attributions_occ_sdi.squeeze().cpu().detach().numpy(), (1, 2, 0))\n",
    "    attr_fe = np.transpose(attributions_occ_fe.squeeze().cpu().detach().numpy(), (1, 2, 0))\n",
    "    input_img_np = np.transpose(input_img.squeeze().cpu().detach().numpy(), (1, 2, 0))\n",
    "    \n",
    "    # Create a figure and axes\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(9, 4.5))\n",
    "    \n",
    "    # Plot the original image\n",
    "    ax.imshow(input_img_np)\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Overlay the positive attributions for Elastic Modulus (EM) in blue\n",
    "    viz.visualize_image_attr(\n",
    "        attr_em,\n",
    "        input_img_np,\n",
    "        method=\"blended_heat_map\",\n",
    "        sign=\"positive\",\n",
    "        show_colorbar=True,\n",
    "        fig_size=(9, 4.5),\n",
    "        use_pyplot=False,\n",
    "        plt_fig_axis=(fig, ax),\n",
    "        cmap='Blues'\n",
    "    )\n",
    "    plt.savefig('Captum_Emod'+str(test_image_number)+'.png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    # Create a figure and axes\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(9, 4.5))\n",
    "    # Plot the original image\n",
    "    ax.imshow(input_img_np)\n",
    "    ax.axis('off')\n",
    "    # Overlay the positive attributions for Strain at Damage Initiation (SDI) in green\n",
    "    viz.visualize_image_attr(\n",
    "        attr_sdi,\n",
    "        input_img_np,\n",
    "        method=\"blended_heat_map\",\n",
    "        sign=\"positive\",\n",
    "        show_colorbar=True,\n",
    "        fig_size=(9, 4.5),\n",
    "        use_pyplot=False,\n",
    "        plt_fig_axis=(fig, ax),\n",
    "        cmap='Greens'\n",
    "    )\n",
    "    plt.savefig('Captum_SDI'+str(test_image_number)+'.png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    # Create a figure and axes\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(9, 4.5))\n",
    "    # Plot the original image\n",
    "    ax.imshow(input_img_np)\n",
    "    ax.axis('off')\n",
    "    # Overlay the positive attributions for Fracture Energy (FE) in red\n",
    "    viz.visualize_image_attr(\n",
    "        attr_fe,\n",
    "        input_img_np,\n",
    "        method=\"blended_heat_map\",\n",
    "        sign=\"positive\",\n",
    "        show_colorbar=True,\n",
    "        fig_size=(9, 4.5),\n",
    "        use_pyplot=False,\n",
    "        plt_fig_axis=(fig, ax),\n",
    "        cmap='Reds'\n",
    "    )\n",
    "    plt.savefig('Captum_FE'+str(test_image_number)+'.png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    # Add a single colorbar for the combined plot\n",
    "    #sm = plt.cm.ScalarMappable(cmap='coolwarm')\n",
    "    #sm.set_array([])\n",
    "    #sm.set_clim(0.9999999, 1.0) \n",
    "    #fig.colorbar(sm, ax=ax, orientation='vertical')\n",
    "\n",
    "    print(np.min(attr_fe))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
